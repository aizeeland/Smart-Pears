{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFiC7uWxOhA7"
      },
      "source": [
        "# Pear Instance Segmentation with COCO dataformat\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC9_kJCCOn0r"
      },
      "source": [
        "## Install detectron2\n",
        "\n",
        "> **Important**: If you're running on a local machine, be sure to follow the [installation instructions](https://github.com/facebookresearch/detectron2/blob/master/INSTALL.md). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "print('Installation ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7L0fpBqOvXL"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-sSjm1MOwMv"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://smartpears.s3.eu-west-1.amazonaws.com/Pears.zip\n",
        "!unzip Pears.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO2z7zp-Pjzt"
      },
      "source": [
        "## Register data-set\n",
        "\n",
        "In order to use a dataset with Detectron2 we need to register it. For more information check out the official documentation.\n",
        "\n",
        "You can change the single_flag variable to use the single or multiple pear dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbjSnmZVPlFu"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "#bool to switch between single and multiple pears dataset\n",
        "single_flag = False\n",
        "\n",
        "\n",
        "for d in [\"train\", \"test\"]:\n",
        "    if single_flag == True:\n",
        "        register_coco_instances(f\"Pears_Single_{d}\", {}, f\"Pears/Single/{d}.json\", f\"Pears/Single/{d}\")\n",
        "    else:\n",
        "        register_coco_instances(f\"Pears_Multiple_{d}\", {}, f\"Pears/Multiple/{d}.json\", f\"Pears/Multiple/{d}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D0eg3COlajty",
        "outputId": "32b0b08f-d1e6-48b2-e084-8f8fa8978219"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "\n",
        "\n",
        "if single_flag == True:\n",
        "    dataset_dicts = DatasetCatalog.get(\"Pears_Single_train\")\n",
        "    peer_metadata = MetadataCatalog.get(\"Pears_Single_train\")\n",
        "else:\n",
        "    dataset_dicts = DatasetCatalog.get(\"Pears_Multiple_train\")\n",
        "    peer_metadata = MetadataCatalog.get(\"Pears_Multiple_train\")\n",
        "\n",
        "for d in random.sample(dataset_dicts, 4):\n",
        "    #print('afbeelding d', d)\n",
        "\n",
        "    seg_array = d['annotations'][0]['segmentation'][0]\n",
        "    #print(seg_array)\n",
        "    re_array = []\n",
        "    #print(len(seg_array))\n",
        "    for i in range(len(seg_array)):\n",
        "        #print(seg_array[i])\n",
        "        if i % 2 == 0:\n",
        "            re_array.extend([float((seg_array[i]) *1.00 )- 0])\n",
        "        else:\n",
        "            re_array.extend([float((seg_array[i]) *1.00 )+ 0])\n",
        "\n",
        "        \n",
        "    #re_array = re_array.reverse()\n",
        "    #print('re_array', re_array)\n",
        "\n",
        "    d['annotations'][0]['segmentation'][0] = re_array\n",
        "\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    v = Visualizer(img, metadata=peer_metadata, scale=1.0)\n",
        "    v = v.draw_dataset_dict(d)\n",
        "    print(v)\n",
        "    plt.figure(figsize = (14, 10))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image(), cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7EmsuFlqgL5"
      },
      "source": [
        "## Train model\n",
        "\n",
        "Now, let's fine-tune a pretrained FasterRCNN instance segmentation model on the microcontroller data-set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB7w2PrWaHFz",
        "outputId": "164ade8f-873a-4cb2-dc2e-b472cf7bcde0"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "if single_flag == True: \n",
        "    cfg.DATASETS.TRAIN = (\"Pears_Single_train\",)\n",
        "else:\n",
        "    cfg.DATASETS.TRAIN = (\"Pears_Multiple_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNUMlT5IqlmY"
      },
      "source": [
        "## Use model for inference\n",
        "\n",
        "Now, we can perform inference on our validation set by creating a predictor object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_25-2_L0aJtI"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 \n",
        "if single_flag == True: \n",
        "    cfg.DATASETS.TEST = (\"Pears_Single_test\", )\n",
        "else:\n",
        "    cfg.DATASETS.TEST = (\"Pears_Multiple_test\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qlfj_NyvcBIp",
        "outputId": "7612ad11-0b02-42c8-bd4a-da18bca25e3c"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "if single_flag == True: \n",
        "    dataset_dicts = DatasetCatalog.get(\"Pears_Single_test\")\n",
        "else:\n",
        "    dataset_dicts = DatasetCatalog.get(\"Pears_Multiple_test\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=peer_metadata, \n",
        "                   scale=1.0, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    print('filename: ', 'output_' + d[\"file_name\"] )\n",
        "    cv2.imwrite(d[\"file_name\"].replace('.jpg', '_output.jpg') ,cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Microcontroller Instance Segmentation with COCO dataformat.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
